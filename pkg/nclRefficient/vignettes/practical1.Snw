%\VignetteIndexEntry{practical1}
%!Snw weave = knitr
%\VignetteEngine{knitr::knitr}
\documentclass[a4paper,justified,openany]{tufte-handout}

<<setup, include=FALSE, cache=FALSE>>=
library(knitr)
options(replace.assign=FALSE,width=50)

opts_chunk$set(fig.path='figure/graphics-', 
               cache.path='cache/graphics-', 
               fig.align='center', 
               dev='pdf', fig.width=5, fig.height=5, 
               fig.show='hold', cache=FALSE, par=TRUE)
knit_hooks$set(crop=hook_pdfcrop)

knit_hooks$set(par=function(before, options, envir){
    if (before && options$fig.show!='none') {
        par(mar=c(3,3,2,1),cex.lab=.95,cex.axis=.9,
            mgp=c(2,.7,0),tcl=-.01, las=1)
}}, crop=hook_pdfcrop)
@
<<echo=FALSE>>=
#knit_theme$set("bw.css")
@

\usepackage{amsmath}

% Set up the images/graphics package
\usepackage{graphicx}
\setkeys{Gin}{width=\linewidth,totalheight=\textheight,keepaspectratio}
\graphicspath{{../graphics/}}

\title{Efficient R: practical sheet} 
\author[Dr Colin Gillespie]{Dr Colin S.
  Gillespie}
\date{}  % if the \date{} command is left out, the current date will be used

% The following package makes prettier tables.  We're all about the bling!
\usepackage{booktabs}

% The units package provides nice, non-stacked fractions and better spacing
% for units.
\usepackage{units}

% The fancyvrb package lets us customize the formatting of verbatim
% environments.  We use a slightly smaller font.
\usepackage{fancyvrb}
\fvset{fontsize=\normalsize}
\newcommand{\cc}{\texttt}
\graphicspath{{../graphics/}}
\setcounter{secnumdepth}{2}

\usepackage{microtype}
\begin{document}

\maketitle% this prints the handout title, author, and date
\bigskip

\noindent Before starting the questions, make sure you can load the \texttt{rbenchmark} package
<<>>=
library(rbenchmark)
@

\noindent and have installed the course R package. 

<<eval=FALSE, tidy=FALSE>>=
##Windows & Linux users
install.packages("nclRefficient", 
                 repos="http://R-Forge.R-project.org")
##Apple users 
install.packages("nclRefficient", 
                 repos="http://R-Forge.R-project.org", 
                 type="source")
@ 

\noindent To load the package, use

<<>>=
library(nclRefficient)
@ 


\noindent Each practical corresponds to a chapter in the notes.

\section*{Practical 1}


\begin{enumerate}
\item Reproduce the timing results in chapter 1 using the \texttt{benchmark} function from the \texttt{rbenchmark} package.
\item \textbf{Case study} In this example, we are going to investigate loading a large data frame. First, we'll generate a large matrix of random numbers and save it as a csv file:\sidenote{If setting \cc{N=1e6} is too large for your machine, reduce it at bit. For example, \cc{N=50,000}.}
<<practical1, cache=TRUE>>=
N = 1e5
m = as.data.frame(matrix(runif(N), ncol=1000))
write.csv(m, file="example.csv", row.names=FALSE)
@
\noindent We can read the file the back in again using \texttt{read.csv}:
<<cache=TRUE>>=
dd = read.csv("example.csv")
@
\noindent To get a baseline result, time the \cc{read.csv} function call above. 


We will now look ways of speeding up this step.
\begin{enumerate}
\item Use the \texttt{nrows} argument to set the number of rows that will be read from your file.\sidenote{Hint, use \cc{nrow(m)} to determine how many rows are in your matrix.}
\item Set \texttt{comment.char=""} to turn off interpretation of comments.
\item Explicitly define the classes of each column using \texttt{colClasses} in \texttt{read.csv}, for example, if we have 1000 columns that all have data type numeric, then:
<<cache=TRUE,results='hide', tidy=FALSE>>=
read.csv(file="example.csv", 
         colClasses=rep("numeric", 1000))
@
\item Use the \cc{save} and \cc{load} functions:
<<cache=TRUE>>=
save(m, file="example.RData")
load(file="example.RData")
@
\end{enumerate}
Which of the above give the biggest speed-ups? Are there any downsides to using these techniques? Do your results depend on the number of columns or the number of rows?
\end{enumerate}

\newpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%Practical 2
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{Practical 2}

\begin{enumerate}
\item In this question, we'll compare matrices and data frames. Suppose we have a matrix, \texttt{d\_m} 
<<>>=
##For fast computers
#d_m = matrix(1:1000000, ncol=1000)
##Slower computers
d_m = matrix(1:10000, ncol=100)
dim(d_m)
@
and a data frame \texttt{d\_df}:
<<>>=
d_df = as.data.frame(d_m)
colnames(d_df) = paste("c", 1:ncol(d_df), sep="")
@
\begin{enumerate}
\item Using the following code, calculate the relative differences between selecting the first column/row of a data frame and matrix. 
<<results='hide', tidy=FALSE>>=
benchmark(replications=1000, 
          d_m[1,], d_df[1,], d_m[,1], d_df[,1],
          columns=c('test', 'elapsed', 'relative'))
@
\noindent Can you explain the result? Try varying the number of replications.

\item When selecting columns in a data frame, there are a few different methods. For example, 
<<results='hide'>>=
d_df$c10
d_df[,10]
d_df[,"c10"]
d_df[,colnames(d_df) == "c10"]
@
Compare these four methods.

\end{enumerate}
<<echo=FALSE>>=
n = 1
@

\item Consider the following piece of code:
<<tidy=FALSE>>=
a = c()
for(i in 1:n)
  a = c(a, 2 * pi * sin(i))
@
\noindent This code calculates the values:
\[
2\pi \sin(1), 2 \pi \sin(2), 2 \pi sin(3), \ldots, 2 \pi sin(n)
\]
and stores them in a vector. Two obvious ways of speeding up this code are:
\begin{itemize}
\item Pre-allocate the vector \texttt{a} for storing your results.
\item Remove $2 \times \pi$ from the loop, i.e. at the end of the loop have the statement: \texttt{2*pi*a}.
\end{itemize}
Try the above techniques for speeding up the loop. Vary $n$ and plot your results.
\item R is an interpreted language; this means that the interpreter executes the program source code directly, statement by statement. Therefore, every function call takes time.\sidenote{This example is for illustrative proposes. Please don't start worrying about comments and brackets.} Consider these three examples:
<<cache=TRUE, tidy=FALSE>>=
n = 1e6
## Example 1
I = 0
for(i in 1:n) {
  10
  I = I + 1
}
## Example 2
I = 0
for(i in 1:n){ 
  ((((((((((10)))))))))) 
  I = I + 1
}
## Example 3
I = 0
for(i in 1:n){ 
  ##This is a comment
  ##But it is still parsed
  ##So takes time
  ##But not a lot
  ##So don't worry!
  10
  I = I + 1
}
@
\noindent Using the \texttt{benchmark} function, time these three examples.
\end{enumerate}
\newpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%Practical 3
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section*{Practical 3: parallel programming}


\begin{enumerate}
\item  To begin, load the \texttt{parallel} package and determine how many cores you have
<<results='hide'>>=
library(parallel)
detectCores()
@
\item Run the parallel \texttt{apply} example in the notes. 
\begin{itemize}
\item On your machine, what value of \texttt{N} do you need to use to make the parallel code run quicker than the standard serial version?
\item When I ran the benchmarks, I didn't include the \texttt{makeCluster} and \texttt{stopCluster} functions calls. Include these calls in your timings. How does this affect your benchmarks?
\end{itemize}
\item Run the dice game Monte-Carlo example in the notes. Vary the parameter \texttt{M}.\sidenote{Try setting \texttt{M=50} and varying \texttt{N}.} 
\end{enumerate}


\section*{Solutions}

Solutions are contained within this package:
<<eval=FALSE>>=
library(nclRefficient)
vignette("solutions1", package="nclRefficient")
@



\end{document}
